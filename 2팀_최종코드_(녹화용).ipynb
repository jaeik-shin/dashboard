{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2493ebce-d39a-41e3-beb0-c0c0a1adcb09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Dress.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile Dress.py\n",
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "import os\n",
    "import io\n",
    "import shutil\n",
    "import requests\n",
    "import psutil\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from chromadb import Client\n",
    "import streamlit as st\n",
    "import time\n",
    "\n",
    "from openai import OpenAI\n",
    "from langchain.chains import LLMChain, StuffDocumentsChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import CohereEmbeddings\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# API í‚¤ ë° í˜¸ìŠ¤íŠ¸ êµ¬ì„±\n",
    "STABILITY_KEY = 'sk-FqJKNUmX1R4wwu9dvNMaL8YcnWLNyfBkDhQUCyZn1m1tH9Gt'\n",
    "GPT_API_KEY = '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'\n",
    "STABILITY_API_HOST = 'https://api.stability.ai/v2beta/stable-image/edit/inpaint'\n",
    "COHERE_API_KEY = \"UPsAF7uP6CNmKw6HMOXy5hqRIJRM8yuPkzLeXD6K\"\n",
    "\n",
    "def create_mask_from_image(image):\n",
    "    \"\"\"\n",
    "    ì´ë¯¸ì§€ì—ì„œ ì–¼êµ´ê³¼ ë°”ë”” ì˜ì—­ì„ ë§ˆìŠ¤í¬ë¡œ ë§Œë“œëŠ” í•¨ìˆ˜\n",
    "    \n",
    "    ë§¤ê°œë³€ìˆ˜ image (PIL.Image): ì…ë ¥ ì´ë¯¸ì§€\n",
    "    ë°˜í™˜ê°’ numpy.ndarray: ì–¼êµ´ê³¼ ë°”ë”” ì˜ì—­ì´ ë§ˆìŠ¤í‚¹ëœ numpy ë°°ì—´ ì´ë¯¸ì§€\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # ì‚¬ë‹¤ë¦¬ê¼´ ìƒì„± ì „ ì „ì²˜ë¦¬\n",
    "        face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml') # ì–¼êµ´ ê°ì§€ìš© Haar Cascade ë¶„ë¥˜ê¸° ë¡œë“œ\n",
    "        img = np.array(image)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) # ì´ë¯¸ì§€ ì–¼êµ´ ê°ì§€ë¥¼ ìœ„í•´ í‘ë°± ì²˜ë¦¬\n",
    "        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30)) # ì‚¬ê°í˜• ì¢Œí‘œ(ì–¼êµ´ ê°ì§€)\n",
    "        mask = np.zeros_like(img[:, :, 0], dtype=np.uint8)  # ì›ë³¸ ì´ë¯¸ì§€ì™€ ë™ì¼í•œ í¬ê¸°ì˜ ê²€ì •ìƒ‰ ë§ˆìŠ¤í¬ ìƒì„±   ### ì¤‘ìš” !!\n",
    "\n",
    "        # ì‚¬ë‹¤ë¦¬ê¼´ ë§ˆìŠ¤í‚¹ ìƒì„±\n",
    "        for (x, y, w, h) in faces:\n",
    "            cv2.rectangle(mask, (x, y), (x + w, y + h), 0, thickness=cv2.FILLED)  # ì–¼êµ´ ì˜ì—­ì„ ê²€ì •ìƒ‰(0)ìœ¼ë¡œ ì±„ì›€\n",
    "             # ë°”ë”” ì˜ì—­ ì‹œì‘ì ê³¼ ëì  ì„¤ì •\n",
    "            body_start_y = y + h + 20  \n",
    "            body_end_y = img.shape[0]\n",
    "            body_width_margin = int(3 * w)\n",
    "             # ë°”ë”” ì˜ì—­ì— ëŒ€í•œ ì‚¬ë‹¤ë¦¬ê¼´ ì¢Œí‘œ ì„¤ì •\n",
    "            top_left = (x - body_width_margin // 2, body_start_y)         # ì¢Œì¸¡ ìƒë‹¨\n",
    "            top_right = (x + w + body_width_margin // 2, body_start_y)    # ìš°ì¸¡ ìƒë‹¨\n",
    "            bottom_left = (x - body_width_margin, body_end_y)            # ì¢Œì¸¡ í•˜ë‹¨\n",
    "            bottom_right = (x + w + body_width_margin, body_end_y)       # ìš°ì¸¡ í•˜ë‹¨\n",
    "            # ì‚¬ë‹¤ë¦¬ê¼´ ë„í˜•ìœ¼ë¡œ ì±„ì›€\n",
    "            points = np.array([top_left, top_right, bottom_right, bottom_left], np.int32)\n",
    "            points = points.reshape((-1, 1, 2))\n",
    "            cv2.fillPoly(mask, [points], 255)   # cv2.fillPoly() í•¨ìˆ˜ëŠ” OpenCVì—ì„œ ì œê³µí•˜ëŠ” í•¨ìˆ˜ë¡œ, ë‹¤ê°í˜•(Polygon) ì˜ì—­ì„ íŠ¹ì • ìƒ‰ìƒìœ¼ë¡œ ì±„ìš¸ ë•Œ ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
    "\n",
    "        return mask\n",
    "    except Exception as e:\n",
    "        st.error(f\"ë§ˆìŠ¤í¬ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        return None\n",
    "\n",
    "def send_generation_request(host, params, files=None):\n",
    "    \"\"\"\n",
    "    ì´ë¯¸ì§€ ìƒì„± API ìš”ì²­ í•¨ìˆ˜\n",
    "    \n",
    "    ë§¤ê°œë³€ìˆ˜\n",
    "    host (str): API ì—”ë“œí¬ì¸íŠ¸ URL\n",
    "    params (dict): API ìš”ì²­ì— ì‚¬ìš©ë  íŒŒë¼ë¯¸í„°\n",
    "    files (dict, optional): ì—…ë¡œë“œí•  íŒŒì¼ ë°ì´í„°ë¥¼ í¬í•¨í•˜ëŠ” ë”•ì…”ë„ˆë¦¬\n",
    "    \n",
    "    ë°˜í™˜ê°’\n",
    "    requests.Response: APIë¡œë¶€í„°ì˜ ì‘ë‹µ ê°ì²´\n",
    "    \"\"\"\n",
    "    headers = {\"Accept\": \"image/*\", \"Authorization\": f\"Bearer {STABILITY_KEY}\"}\n",
    "    files = files or {}\n",
    "    \n",
    "    for key in ['image', 'mask']:\n",
    "        if key in files and isinstance(files[key], Image.Image): # 'image'ì™€ 'mask' í‚¤ì— í•´ë‹¹í•˜ëŠ” íŒŒì¼ ë°ì´í„°ë¥¼ í™•ì¸\n",
    "            img_bytes = io.BytesIO()\n",
    "            files[key].save(img_bytes, format=\"PNG\")\n",
    "            img_bytes.seek(0)\n",
    "            files[key] = img_bytes\n",
    "    \n",
    "    files = files or {\"none\": ''}\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(host, headers=headers, files=files, data=params)\n",
    "        response.raise_for_status()\n",
    "        return response\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        st.error(f\"ì´ë¯¸ì§€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        return None\n",
    "\n",
    "def translate_to_english(korean_prompt):\n",
    "    \"\"\"\n",
    "    í•œêµ­ì–´ í…ìŠ¤íŠ¸ë¥¼ ì˜ì–´ë¡œ ë²ˆì—­í•˜ëŠ” í•¨ìˆ˜\n",
    "    \n",
    "    ë§¤ê°œë³€ìˆ˜  \n",
    "    korean_prompt : ë²ˆì—­í•  í•œêµ­ì–´ í…ìŠ¤íŠ¸  \n",
    "    \n",
    "    ë°˜í™˜ê°’  \n",
    "    str: ë²ˆì—­ëœ ì˜ì–´ í…ìŠ¤íŠ¸  \n",
    "    \"\"\"\n",
    "    headers = {\"Content-Type\": \"application/json\",\"Authorization\": f\"Bearer {GPT_API_KEY}\"}\n",
    "    # gptëª¨ë¸ ë° ë©”ì„¸ì§€ ì…ë ¥ (í•œêµ­ì–´ í…ìŠ¤íŠ¸ë¥¼ ì˜ì–´ë¡œ ë²ˆì—­í•˜ë„ë¡ ìš”ì²­)\n",
    "    data = {\"model\": \"gpt-4\",\"messages\": [{\"role\": \"user\", \"content\": f\"Translate the following text to English: {korean_prompt}\"}]}\n",
    "    # openai ì‘ë‹µ ìš”ì²­ ë° ë°˜í™˜\n",
    "    try:\n",
    "        response = requests.post(\"https://api.openai.com/v1/chat/completions\", json=data, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        st.error(f\"ë²ˆì—­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        return korean_prompt\n",
    "\n",
    "def safely_remove_directory(dir_path):\n",
    "    \"\"\"ê°•ì œë¡œ ë””ë ‰í† ë¦¬ë¥¼ ì‚­ì œí•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    if os.path.exists(dir_path):\n",
    "        # í”„ë¡œì„¸ìŠ¤ì—ì„œ ë””ë ‰í† ë¦¬ë¥¼ ì ìœ í•˜ê³  ìˆëŠ”ì§€ í™•ì¸\n",
    "        for proc in psutil.process_iter():    #  psutil :ì‹œìŠ¤í…œ í”„ë¡œì„¸ìŠ¤ ë° ë¦¬ì†ŒìŠ¤ ê´€ë¦¬ë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "            try:\n",
    "                for open_file in proc.open_files():\n",
    "                    if dir_path in open_file.path:\n",
    "                        proc.terminate()  # í”„ë¡œì„¸ìŠ¤ ê°•ì œ ì¢…ë£Œ\n",
    "                        time.sleep(0.5)  # ì§€ì—° ì‹œê°„ ì¶”ê°€\n",
    "            except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):\n",
    "                pass\n",
    "        # ë””ë ‰í† ë¦¬ ì‚­ì œ\n",
    "        shutil.rmtree(dir_path, ignore_errors=True)   # shutil : íŒŒì¼ ë° ë””ë ‰í† ë¦¬ ì¡°ì‘ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ,  ì˜¤ë¥˜ True ë¬´ì‹œ\n",
    "        time.sleep(0.5)\n",
    "\n",
    "def initialize_vector_store(pdf_path='data/Dress.pdf', vectorstore_dir='./VectorStores'): #ì§€ì •ëœ íŒŒì¼ ë° ì§€ì •ëœ ë²¡í„°ì €ì¥ì†Œí´ë”\n",
    "    \"\"\"\n",
    "    PDF íŒŒì¼ì„ ë¡œë“œí•˜ê³  ë²¡í„° ì €ì¥ì†Œë¥¼ ì´ˆê¸°í™”í•˜ëŠ” í•¨ìˆ˜.\n",
    "    ë§¤ê°œë³€ìˆ˜\n",
    "    pdf_path : PDF íŒŒì¼ ê²½ë¡œ\n",
    "    vectorstore_dir : ë²¡í„° ì €ì¥ì†Œ ë””ë ‰í† ë¦¬ ê²½ë¡œ\n",
    "    ë°˜í™˜ê°’\n",
    "    Chroma: ì´ˆê¸°í™”ëœ ë²¡í„° ì €ì¥ì†Œ ê°ì²´\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # PDF íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸\n",
    "        if not os.path.exists(pdf_path):\n",
    "            raise FileNotFoundError(f\"PDF íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {pdf_path}\")\n",
    "        \n",
    "        # ê¸°ì¡´ ë²¡í„° ì €ì¥ì†Œ ì‚­ì œ\n",
    "        if os.path.exists(vectorstore_dir):\n",
    "            shutil.rmtree(vectorstore_dir, ignore_errors=True)\n",
    "\n",
    "        # PDF íŒŒì¼ ë¡œë“œ ë° ë¶„í• \n",
    "        loader = PyPDFLoader(pdf_path)\n",
    "        documents = loader.load()\n",
    "        splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)  # ì²­í¬ì‚¬ì´ì¦ˆ ì¡°ì •!!!!!!!!!!!!!!!!!!!!!!!\n",
    "        texts = splitter.split_documents(documents)\n",
    "\n",
    "        # Cohere Embeddings ìƒì„±\n",
    "        embeddings = CohereEmbeddings(cohere_api_key=COHERE_API_KEY, \n",
    "                                      user_agent=\"langchain_cohere/0.1\"           # ë§¤ìš° ì¤‘ìš” (ì—†ìœ¼ë©´ ì˜¤ë¥˜ë°œìƒ)\n",
    "        )\n",
    "\n",
    "        # ChromaClientë¡œ ë²¡í„° ì €ì¥ì†Œ ìƒì„±\n",
    "        chroma_client = Client()  \n",
    "        # ChromaDB í´ë¼ì´ì–¸íŠ¸ëŠ” í•„ìˆ˜ëŠ” ì•„ë‹ˆì§€ë§Œ, ë²¡í„° ë°ì´í„°ì˜ ì €ì¥ê³¼ ìœ ì‚¬ë„ ê²€ìƒ‰ì„ íš¨ìœ¨ì ìœ¼ë¡œ ìˆ˜í–‰í•˜ë©° ì„¸ë¶€ ì„¤ì • ê´€ë¦¬ê°€ í•„ìš”í•œ ê²½ìš° ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
    "        chroma_client.heartbeat()  # Chroma ì—°ê²° í™•ì¸\n",
    "\n",
    "        vectorstore = Chroma.from_documents(\n",
    "            documents=texts,\n",
    "            embedding=embeddings,\n",
    "            persist_directory=vectorstore_dir,\n",
    "            client=chroma_client\n",
    "        )\n",
    "\n",
    "        # ì €ì¥ì†Œ ì €ì¥\n",
    "        vectorstore.persist()\n",
    "        return vectorstore\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ë²¡í„° ì €ì¥ì†Œ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        return None\n",
    "\n",
    "def create_retrieval_chain(vectorstore):\n",
    "    \"\"\"RAG ê²€ìƒ‰ ì²´ì¸ì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    combined_prompt = PromptTemplate(\n",
    "        template=\"\"\"\n",
    "        ì²´í˜• ë¶„ì„ ê²°ê³¼ì™€ ì¶”ê°€ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ìŠ¤íƒ€ì¼ê³¼ ì–´ìš¸ë¦¬ëŠ” ì›¨ë”©ë“œë ˆìŠ¤ë¥¼ ì¶”ì²œí•´ì£¼ì„¸ìš”.\n",
    "        ë¬¸ì„œ ë‚´ìš©: {context}\n",
    "\n",
    "        ì²´í˜• ë¶„ì„: {body_analysis}\n",
    "        ì¶”ê°€ ì •ë³´: {additional_info}\n",
    "\n",
    "        ì§ˆë¬¸: ì‚¬ìš©ìì—ê²Œ ì–´ìš¸ë¦¬ëŠ” ì›¨ë”©ë“œë ˆìŠ¤ ìŠ¤íƒ€ì¼, ì•…ì„¸ì‚¬ë¦¬, í—¤ì–´ìŠ¤íƒ€ì¼ì„ ì¶”ì²œí•´ì£¼ì„¸ìš”.\n",
    "        \"\"\",\n",
    "        input_variables=[\"context\", \"body_analysis\", \"additional_info\"] #input_variablesëŠ” í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì— í•„ìš”í•œ ì…ë ¥ê°’ì˜ ì´ë¦„ì„ ì •ì˜(í”„ë¡¬í”„íŠ¸ ì•ˆì— ë„£ìœ¼ë©´ ì´ê³³ì—ë„ ë„£ì„ê²ƒ!)\n",
    "    )\n",
    "    \n",
    "    llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.3, openai_api_key=GPT_API_KEY)\n",
    "    llm_chain = LLMChain(llm=llm, prompt=combined_prompt)         #     ì—¬ê¸°ì— í”„ë¡¬í”„íŠ¸ ì§ì ‘ì ìœ¼ë¡œ ë“¤ì–´ê°\n",
    "    \n",
    "    # ì—¬ëŸ¬ ë¬¸ì„œë¥¼ í•˜ë‚˜ì˜ í”„ë¡¬í”„íŠ¸ë¡œ ê²°í•©í•´ LLMì— ì „ë‹¬í•˜ëŠ” ì²´ì¸\n",
    "    return StuffDocumentsChain(llm_chain=llm_chain, document_variable_name=\"context\")\n",
    "    \n",
    "\n",
    "def send_gpt_request_with_rag(body_analysis, additional_info, pdf_path='data/Dress.pdf', vectorstore_dir='./VectorStores'):\n",
    "    \"\"\"RAG ê¸°ë°˜ ë“œë ˆìŠ¤ ì¶”ì²œ í•¨ìˆ˜\"\"\"\n",
    "    try:\n",
    "        # ë²¡í„° ì €ì¥ì†Œ ì´ˆê¸°í™”\n",
    "        vectorstore = initialize_vector_store(pdf_path, vectorstore_dir)\n",
    "        if vectorstore is None:\n",
    "            return \"ë²¡í„° ì €ì¥ì†Œë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "        \n",
    "        # RAG ì²´ì¸ ìƒì„±\n",
    "        rag_chain = create_retrieval_chain(vectorstore)\n",
    "        \n",
    "        # ë¬¸ì„œ ê²€ìƒ‰ ë° RAG ì²´ì¸ ì‹¤í–‰\n",
    "        retrieved_docs = vectorstore.similarity_search(\"ì›¨ë”©ë“œë ˆìŠ¤ ìŠ¤íƒ€ì¼ ì¶”ì²œ\")\n",
    "        \n",
    "        rag_result = rag_chain({\n",
    "            \"input_documents\": retrieved_docs,  # ê²€ìƒ‰ëœ ë¬¸ì„œ\n",
    "            \"body_analysis\": body_analysis,     # ì²´í˜• ë¶„ì„ ì •ë³´\n",
    "            \"additional_info\": additional_info  # ì¶”ê°€ ì‚¬ìš©ì ì •ë³´\n",
    "        })\n",
    "\n",
    "        # ê²°ê³¼ ì •ë¦¬\n",
    "        korean_recommendation = rag_result['output_text'] # RAG ê²°ê³¼ì—ì„œ ì¶œë ¥ëœ í•œêµ­ì–´ ì¶”ì²œ ê²°ê³¼ë¥¼ ì €ì¥\n",
    "        english_translation = translate_to_english(korean_recommendation)  # ë²ˆì—­ í•¨ìˆ˜ í˜¸ì¶œí•˜ì—¬ ì¶”ì²œ ê²°ê³¼ë¥¼ ì˜ì–´ë¡œ ë²ˆì—­\n",
    "\n",
    "        # ê²°ê³¼ë¥¼ PDF ë°ì´í„°ì—ì„œ ì¶”ì¶œëœ ì„¸ë¶€ ì •ë³´ë¡œ ì •ë¦¬\n",
    "        korean_recommendation = f\"\"\"\n",
    "        ğŸŒŸ ì²´í˜•ì— ì–´ìš¸ë¦¬ëŠ” ì›¨ë”©ë“œë ˆìŠ¤ ì¶”ì²œ ê²°ê³¼ ğŸŒŸ\n",
    "\n",
    "        ì²´í˜• ë¶„ì„ ê²°ê³¼: {body_analysis}\n",
    "        ì¶”ê°€ ì •ë³´: {additional_info}\n",
    "\n",
    "        ğŸ”¹ ì¶”ì²œ ë“œë ˆìŠ¤ ìŠ¤íƒ€ì¼\n",
    "        {korean_recommendation}\n",
    "\n",
    "        ğŸ”¹ ì¶”ì²œ ì•¡ì„¸ì„œë¦¬\n",
    "        - í‹°ì•„ë¼: ì‘ê³  ì„¬ì„¸í•œ ë‹¤ì´ì•„ëª¬ë“œ ì¥ì‹\n",
    "        - ëª©ê±¸ì´: í•˜íŠ¸ë„¥ì—ëŠ” ì‹¬í”Œí•œ íœë˜íŠ¸ ëª©ê±¸ì´, ìŠ¤í€˜ì–´ë„¥ì—ëŠ” ê¸¸ê²Œ ëŠ˜ì–´ì§„ ëª©ê±¸ì´\n",
    "        - ê·€ê±¸ì´: í¬ë¦¬ìŠ¤íƒˆ ë“œë¡­ ê·€ê±¸ì´ ë˜ëŠ” ì§„ì£¼ ê·€ê±¸ì´\n",
    "\n",
    "        ğŸ”¹ ì¶”ì²œ ìš´ë™\n",
    "        - ì½”ì–´ ê°•í™” ìš´ë™: í”Œë­í¬ 30ì´ˆ 3ì„¸íŠ¸\n",
    "        - í•˜ì²´ ê°•í™” ìš´ë™: ìŠ¤ì¿¼íŠ¸ 10~15íšŒ 3ì„¸íŠ¸\n",
    "\n",
    "        ğŸ”¹ ì¶”ì²œ ì‹ë‹¨\n",
    "        - ì•„ì¹¨: ê·¸ë¦­ ìš”ê±°íŠ¸, ë¸”ë£¨ë² ë¦¬, ì‚¶ì€ ê³„ë€\n",
    "        - ì ì‹¬: ë‹­ê°€ìŠ´ì‚´ ìƒëŸ¬ë“œ, ì•„ë³´ì¹´ë„\n",
    "        - ì €ë…: ì—°ì–´êµ¬ì´, ë¸Œë¡œì½œë¦¬, í€´ë…¸ì•„\n",
    "\n",
    "        ğŸ”¹ í”¼ë¶€ ë° í—¤ì–´ ê´€ë¦¬\n",
    "        - ë¹„íƒ€ë¯¼ C ì„¸ëŸ¼ê³¼ SPF 50+ ì„ í¬ë¦¼\n",
    "        - ë°”ë”” ìŠ¤í¬ëŸ½ ë° ë¡œì…˜ ê´€ë¦¬\n",
    "        - ëª¨ë°œ ì˜ì–‘íŒ© ì£¼ 1íšŒ ì‚¬ìš©\n",
    "        \"\"\"\n",
    "\n",
    "        return korean_recommendation\n",
    "\n",
    "    except Exception as e:\n",
    "        st.error(f\"ì¶”ì²œ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        return \"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "# ë°”ë”” í˜•íƒœ ì •ì˜\n",
    "def classify_body_shape(measurements):\n",
    "    shoulder_width = measurements['shoulder_width']\n",
    "    chest = measurements['chest']\n",
    "    waist = measurements['waist']\n",
    "    hip = measurements['hip']\n",
    "    waist_width = measurements['waist_width']\n",
    "    hip_width = measurements['hip_width']\n",
    "    height = measurements['height']\n",
    "    weight = measurements['weight']\n",
    "    bmi = weight / ((height / 100) ** 2)\n",
    "\n",
    "    if abs(chest - hip) < 10 and chest > waist * 1.2 and abs(waist_width - hip_width) < 5:\n",
    "        body_shape = \"ëª¨ë˜ì‹œê³„í˜•\"\n",
    "    elif shoulder_width > hip:\n",
    "        body_shape = \"ì—­ì‚¼ê°í˜•\"\n",
    "    elif abs(shoulder_width - hip) < 10 and abs(chest - waist) < 10:\n",
    "        body_shape = \"ì§ì‚¬ê°í˜•\"\n",
    "    elif waist / hip >= 0.9:\n",
    "        body_shape = \"ì›í˜•\"\n",
    "    else:\n",
    "        body_shape = \"ê¸°íƒ€\"\n",
    "\n",
    "    if bmi < 18:\n",
    "        size_category = \"ë§ˆë¦„\"\n",
    "    elif 18 <= bmi < 23:\n",
    "        size_category = \"í‘œì¤€\"\n",
    "    elif 23 <= bmi < 25:\n",
    "        size_category = \"ê³¼ì²´ì¤‘\"\n",
    "    else:\n",
    "        size_category = \"ë¹„ë§Œ\"\n",
    "\n",
    "    return f\"{body_shape}\"\n",
    "\n",
    "def main():\n",
    "    st.set_page_config(page_title=\"ì²´í˜•ì— ë§ëŠ” ì›¨ë”© ë“œë ˆìŠ¤ AI ì¶”ì²œ\", page_icon=\"ğŸ‘—\")\n",
    "    st.title(\"âœ¨ì›¨ë”© ë“œë ˆìŠ¤ ì¶”ì²œâœ¨\")\n",
    "\n",
    "    with st.sidebar:\n",
    "        st.header(\"ì‹ ì²´ ì •ë³´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”\")\n",
    "        measurements = {\n",
    "            \"shoulder_width\": st.number_input(\"ì–´ê¹¨ ë„ˆë¹„ (cm)\", min_value=30.0, max_value=80.0, step=0.1),   # ë„“ì€ ë²”ìœ„: 30~80cm\n",
    "            \"chest\": st.number_input(\"ê°€ìŠ´ ë‘˜ë ˆ (cm)\", min_value=70.0, max_value=160.0, step=0.1),         # ë„“ì€ ë²”ìœ„: 70~160cm\n",
    "            \"waist\": st.number_input(\"í—ˆë¦¬ ë‘˜ë ˆ (cm)\", min_value=45.0, max_value=140.0, step=0.1),         # ë„“ì€ ë²”ìœ„: 45~140cm\n",
    "            \"hip\": st.number_input(\"ì—‰ë©ì´ ë‘˜ë ˆ (cm)\", min_value=70.0, max_value=160.0, step=0.1),         # ë„“ì€ ë²”ìœ„: 70~160cm\n",
    "            \"waist_width\": st.number_input(\"í—ˆë¦¬ ë„ˆë¹„ (cm)\", min_value=20.0, max_value=70.0, step=0.1),    # ë„“ì€ ë²”ìœ„: 20~70cm\n",
    "            \"hip_width\": st.number_input(\"ì—‰ë©ì´ ë„ˆë¹„ (cm)\", min_value=30.0, max_value=80.0, step=0.1),    # ë„“ì€ ë²”ìœ„: 30~80cm\n",
    "            \"height\": st.number_input(\"í‚¤ (cm)\", min_value=130.0, max_value=210.0, step=0.1),             # ë„“ì€ ë²”ìœ„: 130~210cm\n",
    "            \"weight\": st.number_input(\"ì²´ì¤‘ (kg)\", min_value=30.0, max_value=150.0, step=0.1),            # ë„“ì€ ë²”ìœ„: 30~150kg\n",
    "        }\n",
    "\n",
    "        face_shape = st.selectbox(\"ì–¼êµ´í˜• ì„ íƒ\", [\"ë‘¥ê·¼í˜•\", \"ê³„ë€í˜•\", \"ê°ì§„í˜•\", \"ì—­ì‚¼ê°í˜•\"])\n",
    "        additional_info = st.text_area(\"ì¶”ê°€ ì •ë³´ (ì˜ˆ: í”¼ë¶€ í†¤, ìŠ¤íƒ€ì¼ ì„ í˜¸ë„ ë“±)\")\n",
    "        image_file = st.file_uploader(\"ì´ë¯¸ì§€ ì—…ë¡œë“œ\", type=[\"jpg\", \"png\", \"jpeg\"])\n",
    "        recommend_button = st.button(\"ì¶”ì²œ ë° ì´ë¯¸ì§€ ìƒì„±\")\n",
    "    \n",
    "    tab1, tab2 = st.tabs([\"ì¶”ì²œ\", \"ì§ˆë¬¸\"])\n",
    "    \n",
    "    with tab1:\n",
    "        # ì´ì „ì— ìƒì„±í•œ í…ìŠ¤íŠ¸ë‚˜ ì´ë¯¸ì§€ê°€ session_stateì— ìˆë‹¤ë©´ í‘œì‹œ\n",
    "        if \"generated_text\" in st.session_state and \"generated_image\" in st.session_state:\n",
    "            st.subheader(\"ì¶”ì²œëœ ì›¨ë”©ë“œë ˆìŠ¤ ìŠ¤íƒ€ì¼\")\n",
    "            st.write(st.session_state[\"generated_text\"])\n",
    "            st.image(st.session_state[\"generated_image\"], caption=\"AIê°€ ì¶”ì²œí•œ ë“œë ˆìŠ¤ë¥¼ ì…ì€ ì•„ë¦„ë‹¤ìš´ ì‹ ë¶€\", use_container_width=True)\n",
    "        else:\n",
    "            # ì¶”ì²œ í™”ë©´ í‘œì‹œ ë°  ì´ë¯¸ì§€ ìƒì„± í•˜ëŠ” ë²„íŠ¼\n",
    "            if recommend_button:\n",
    "                if image_file:\n",
    "                    # ë¡œë”© ì¤‘ ë©”ì„¸ì§€ ì¶œë ¥\n",
    "                    loading_placeholder = st.empty()\n",
    "                    result_placeholder = st.empty()\n",
    "                    \n",
    "                    loading_placeholder.text(\"ğŸ”„ ê²°ê³¼ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤...\")\n",
    "                    time.sleep(3)\n",
    "                    loading_placeholder.empty()  # ë¡œë”© ìƒíƒœ ì§€ìš°ê¸° ìƒˆë¡œìš´ í…ìŠ¤íŠ¸ ì¶œë ¥\n",
    "                    result_placeholder.text(\"ğŸ”„ ê²°ê³¼ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤...\")\n",
    "                    \n",
    "                    try:\n",
    "                        with loading_placeholder.container():\n",
    "                            st.spinner(\"ì¶”ì²œ ë° ì´ë¯¸ì§€ ìƒì„± ì¤‘...\")\n",
    "                            st.progress(0)\n",
    "                        \n",
    "                        time.sleep(1)\n",
    "                        # ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹œì‘\n",
    "                        image = Image.open(image_file)\n",
    "                        mask_image = create_mask_from_image(image)\n",
    "                        mask_pil_image = Image.fromarray(mask_image)\n",
    "                        \n",
    "                        with loading_placeholder.container():\n",
    "                            st.spinner(\"ì¶”ì²œ ìŠ¤íƒ€ì¼ ë¶„ì„ ì¤‘...\")\n",
    "                            st.progress(30)\n",
    "                        # ì¶”ì²œ ìƒì„±\n",
    "                        body_analysis = classify_body_shape(measurements)\n",
    "                        korean_recommendation = send_gpt_request_with_rag(body_analysis, additional_info)\n",
    "                        \n",
    "                        with loading_placeholder.container():\n",
    "                            st.spinner(\"ì´ë¯¸ì§€ ìƒì„± ì¤€ë¹„ ì¤‘...\")\n",
    "                            st.progress(60)\n",
    "                        \n",
    "                        # ì¶”ì²œ ì˜ì–´ë¡œ ë²ˆì—­\n",
    "                        english_translation = translate_to_english(korean_recommendation)\n",
    "                        # ì´ë¯¸ì§€ ìƒì„±\n",
    "                        params = {                                                      # ì´ë¯¸ì§€ ìƒì„± í”„ë¡¬í”„íŠ¸ ë§ì´ë§ì´ Touch í•´ ë³¼ ê²ƒ.\n",
    "                            \"prompt\": english_translation,\n",
    "                            \"negative_prompt\": \"\"\"paintings, sketches, worst quality, low quality, normal quality, lowres, normal quality, monochrome, grayscale, ...\"\"\",\n",
    "                            \"seed\": 0,\n",
    "                            \"mode\": \"mask\",\n",
    "                            \"output_format\": \"jpeg\",\n",
    "                        }\n",
    "                        \n",
    "                        with loading_placeholder.container():\n",
    "                            st.spinner(\"ìµœì¢… ì´ë¯¸ì§€ ìƒì„± ì¤‘...\")\n",
    "                            st.progress(80)\n",
    "                        \n",
    "                        response = send_generation_request(STABILITY_API_HOST, params, files={\"image\": image, \"mask\": mask_pil_image})\n",
    "                        output_image = response.content\n",
    "                        edited_image = Image.open(io.BytesIO(output_image))\n",
    "                        \n",
    "                        # ë¡œë”© ìŠ¤í”¼ë„ˆ ì§€ìš°ê¸°\n",
    "                        loading_placeholder.empty()\n",
    "                        \n",
    "                        # ê²°ê³¼ í‘œì‹œ\n",
    "                        with result_placeholder.container():\n",
    "                            st.subheader(\"ì¶”ì²œëœ ì›¨ë”©ë“œë ˆìŠ¤ ìŠ¤íƒ€ì¼\")\n",
    "                            st.write(korean_recommendation)\n",
    "                            st.image(edited_image, caption=\"ì¶”ì²œ ì´ë¯¸ì§€\", use_container_width=True)\n",
    "    \n",
    "                        # session_stateì— ê²°ê³¼ ì €ì¥ -> íƒ­ ì´ë™ ì‹œ ìœ ì§€\n",
    "                        st.session_state[\"generated_text\"] = korean_recommendation\n",
    "                        st.session_state[\"generated_image\"] = edited_image\n",
    "    \n",
    "                    except Exception as e:\n",
    "                        loading_placeholder.empty()\n",
    "                        st.error(f\"ì˜¤ë¥˜: {e}\")\n",
    "                else:\n",
    "                    st.warning(\"ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.\")\n",
    "            else:\n",
    "                st.info(\"ğŸ“„ ì‚¬ì´ë“œë°”ì—ì„œ ì‹ ì²´ ì •ë³´ì™€ ì´ë¯¸ì§€ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.\")\n",
    "\n",
    "\n",
    "    with tab2:\n",
    "        st.title(\"ê¶ê¸ˆí•œ ê±° ë¬¼ì–´ë´ğŸ’¬\")\n",
    "      \n",
    "        def moderate_message(message):\n",
    "            client = OpenAI(api_key=GPT_API_KEY)\n",
    "            response = client.moderations.create(model='text-moderation-latest', input=message) # OpenAI Moderation API ëª¨ë¸ ì„¤ì •  í˜„ì¬ ê°€ì¥ ì í•©\n",
    "            moderation_result = response.results[0] \n",
    "\n",
    "            if moderation_result.flagged: # ë©”ì‹œì§€ê°€ ë¶€ì ì ˆí•˜ë‹¤ê³  íŒë‹¨ëœ ê²½ìš°\n",
    "                category_type = dict(response.results[0].categories)\n",
    "                categories = [i for i, j in category_type.items() if j]\n",
    "                return False, categories\n",
    "\n",
    "            return True, None\n",
    "        # ë¶€ì ì ˆí•œ ë©”ì‹œì§€ ì°¨ë‹¨\n",
    "        class ModeratedLLMChain(LLMChain):\n",
    "            def moderate_and_generate(self, user_input):\n",
    "                is_safe, categories = moderate_message(user_input)\n",
    "                if not is_safe:                   # ì…ë ¥ì´ ë¶€ì ì ˆí•˜ë©´ ê²½ê³  ë©”ì‹œì§€ ì¶œë ¥\n",
    "                    st.write(f\"ì‚¬ìš©ìì˜ ë©”ì‹œì§€ê°€ ë¶€ì ì ˆí•œ ì½˜í…ì¸ ë¡œ íŒë‹¨ë˜ì–´ ì°¨ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤: {categories}\")\n",
    "                    return \"\"\n",
    "\n",
    "                response = self.predict(question=user_input)\n",
    "\n",
    "                is_safe_ai, categories_ai = moderate_message(response)\n",
    "                if not is_safe_ai:\n",
    "                    st.write(f\"AIì˜ ì‘ë‹µì´ ë¶€ì ì ˆí•œ ì½˜í…ì¸ ë¡œ íŒë‹¨ë˜ì–´ ì°¨ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤: {categories_ai}\")\n",
    "                    return \"\"\n",
    "\n",
    "                # AI ì‘ë‹µ ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ í‘œì‹œ\n",
    "                words = response.split()\n",
    "                chunk_size = 1\n",
    "                full_response = \"\"     # ì „ì²´ ì‘ë‹µì„ ëˆ„ì í•  ë¬¸ìì—´ ì´ˆê¸°í™”\n",
    "                empty = st.empty()\n",
    "\n",
    "                for i in range(0, len(words), chunk_size):\n",
    "                    full_response += \" \".join(words[i:i + chunk_size]) + \" \"\n",
    "                    empty.write(full_response, unsafe_allow_html=True)\n",
    "                    time.sleep(0.1)\n",
    "\n",
    "                return full_response\n",
    "         # gptëª¨ë¸ ìƒì„¸ ì„¤ì •\n",
    "        chat_model = ChatOpenAI(model_name='gpt-4o', api_key=GPT_API_KEY, temperature=0.7)\n",
    "\n",
    "        my_prompt = PromptTemplate(input_variables=[\"chat_history\", \"question\"],\n",
    "                                   template=\"\"\"You are an AI assistant.\n",
    "                                   You are currently having a conversation with a human.\n",
    "                                   Answer the questions.                       \n",
    "                                   chat_history: {chat_history},\n",
    "                                   Human: {question}\n",
    "                                   AI assistant: \"\"\")\n",
    "           \n",
    "        if \"pre_memory\" not in st.session_state:          # ëŒ€í™” ê¸°ë¡ ë©”ëª¨ë¦¬ (ì„¸ì…˜ ìƒíƒœì— ì €ì¥)\n",
    "            st.session_state.pre_memory = ConversationBufferMemory(memory_key=\"chat_history\",return_messages=True)\n",
    "\n",
    "        # ModeratedLLMChain ê°ì²´ ìƒì„± (ëŒ€í™” ë‚´ìš©ì„ í•„í„°ë§í•˜ê³  ì‘ë‹µ ìƒì„±)\n",
    "        moderated_chain = ModeratedLLMChain(llm=chat_model, prompt=my_prompt, memory=st.session_state.pre_memory)\n",
    "\n",
    "        if \"messages\" not in st.session_state:\n",
    "            st.session_state.messages = [\n",
    "                {\"role\": \"assistant\", \"content\": \"ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” ë‹¹ì‹ ì˜ ë“œë ˆìŠ¤ ì¶”ì²œ ì „ë¬¸ AIì…ë‹ˆë‹¤.\"}\n",
    "            ]\n",
    "\n",
    "        for message in st.session_state.messages:\n",
    "            with st.chat_message(message[\"role\"]):\n",
    "                st.write(message[\"content\"])\n",
    "\n",
    "        user_prompt = st.chat_input()    # ì±„íŒ… ì…ë ¥ í•„ë“œ ìƒì„±\n",
    "\n",
    "        if user_prompt is not None:\n",
    "            st.session_state.messages.append({\"role\": \"user\", \"content\": user_prompt})\n",
    "            with st.chat_message(\"user\"):\n",
    "                st.write(user_prompt)\n",
    "\n",
    "        if st.session_state.messages[-1][\"role\"] != \"assistant\":\n",
    "            with st.chat_message(\"assistant\"):\n",
    "                try:\n",
    "                    ai_response = moderated_chain.moderate_and_generate(user_prompt)\n",
    "                    st.session_state.messages.append({\"role\": \"assistant\", \"content\": ai_response})\n",
    "                except Exception as e:\n",
    "                    st.error(f\"LLM ì—ëŸ¬ ë°œìƒ: {e}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":     #\"ì´ íŒŒì¼ì„ í˜¼ì ì‹¤í–‰í•  ë•Œë§Œ ì´ ì½”ë“œë¥¼ ì‹¤í–‰í•´!\" ë¼ëŠ” ëœ»\n",
    "    main()\n",
    "\n",
    "    if not os.path.exists('./VectorStores'):\n",
    "        os.makedirs('./VectorStores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af0445f9-cd2a-4d0a-bc6d-3f2865d1416c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Dress.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile Dress.py\n",
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "import os\n",
    "import io\n",
    "import shutil\n",
    "import requests\n",
    "import psutil\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from chromadb import Client\n",
    "import streamlit as st\n",
    "import time\n",
    "import traceback\n",
    "\n",
    "from openai import OpenAI\n",
    "from langchain.chains import LLMChain, StuffDocumentsChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import CohereEmbeddings\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# API í‚¤ ë° í˜¸ìŠ¤íŠ¸ êµ¬ì„±\n",
    "STABILITY_KEY = 'sk-FqJKNUmX1R4wwu9dvNMaL8YcnWLNyfBkDhQUCyZn1m1tH9Gt'\n",
    "GPT_API_KEY = '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'\n",
    "STABILITY_API_HOST = 'https://api.stability.ai/v2beta/stable-image/edit/inpaint'\n",
    "COHERE_API_KEY = \"UPsAF7uP6CNmKw6HMOXy5hqRIJRM8yuPkzLeXD6K\"\n",
    "\n",
    "def create_mask_from_image(image):\n",
    "    \"\"\"\n",
    "    ì´ë¯¸ì§€ì—ì„œ ì–¼êµ´ê³¼ ë°”ë”” ì˜ì—­ì„ ë§ˆìŠ¤í¬ë¡œ ë§Œë“œëŠ” í•¨ìˆ˜\n",
    "    \n",
    "    ë§¤ê°œë³€ìˆ˜ image (PIL.Image): ì…ë ¥ ì´ë¯¸ì§€\n",
    "    ë°˜í™˜ê°’ numpy.ndarray: ì–¼êµ´ê³¼ ë°”ë”” ì˜ì—­ì´ ë§ˆìŠ¤í‚¹ëœ numpy ë°°ì—´ ì´ë¯¸ì§€\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # ì‚¬ë‹¤ë¦¬ê¼´ ìƒì„± ì „ ì „ì²˜ë¦¬\n",
    "        face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml') # ì–¼êµ´ ê°ì§€ìš© Haar Cascade ë¶„ë¥˜ê¸° ë¡œë“œ\n",
    "        img = np.array(image)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) # ì´ë¯¸ì§€ ì–¼êµ´ ê°ì§€ë¥¼ ìœ„í•´ í‘ë°± ì²˜ë¦¬\n",
    "        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30)) # ì‚¬ê°í˜• ì¢Œí‘œ(ì–¼êµ´ ê°ì§€)\n",
    "        mask = np.zeros_like(img[:, :, 0], dtype=np.uint8)  # ì›ë³¸ ì´ë¯¸ì§€ì™€ ë™ì¼í•œ í¬ê¸°ì˜ ê²€ì •ìƒ‰ ë§ˆìŠ¤í¬ ìƒì„±   ### ì¤‘ìš” !!\n",
    "\n",
    "        # ì‚¬ë‹¤ë¦¬ê¼´ ë§ˆìŠ¤í‚¹ ìƒì„±\n",
    "        for (x, y, w, h) in faces:\n",
    "            cv2.rectangle(mask, (x, y), (x + w, y + h), 0, thickness=cv2.FILLED)  # ì–¼êµ´ ì˜ì—­ì„ ê²€ì •ìƒ‰(0)ìœ¼ë¡œ ì±„ì›€\n",
    "             # ë°”ë”” ì˜ì—­ ì‹œì‘ì ê³¼ ëì  ì„¤ì •\n",
    "            body_start_y = y + h + 20  \n",
    "            body_end_y = img.shape[0]\n",
    "            body_width_margin = int(3 * w)\n",
    "             # ë°”ë”” ì˜ì—­ì— ëŒ€í•œ ì‚¬ë‹¤ë¦¬ê¼´ ì¢Œí‘œ ì„¤ì •\n",
    "            top_left = (x - body_width_margin // 2, body_start_y)         # ì¢Œì¸¡ ìƒë‹¨\n",
    "            top_right = (x + w + body_width_margin // 2, body_start_y)    # ìš°ì¸¡ ìƒë‹¨\n",
    "            bottom_left = (x - body_width_margin, body_end_y)            # ì¢Œì¸¡ í•˜ë‹¨\n",
    "            bottom_right = (x + w + body_width_margin, body_end_y)       # ìš°ì¸¡ í•˜ë‹¨\n",
    "            # ì‚¬ë‹¤ë¦¬ê¼´ ë„í˜•ìœ¼ë¡œ ì±„ì›€\n",
    "            points = np.array([top_left, top_right, bottom_right, bottom_left], np.int32)\n",
    "            points = points.reshape((-1, 1, 2))\n",
    "            cv2.fillPoly(mask, [points], 255)   # cv2.fillPoly() í•¨ìˆ˜ëŠ” OpenCVì—ì„œ ì œê³µí•˜ëŠ” í•¨ìˆ˜ë¡œ, ë‹¤ê°í˜•(Polygon) ì˜ì—­ì„ íŠ¹ì • ìƒ‰ìƒìœ¼ë¡œ ì±„ìš¸ ë•Œ ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
    "\n",
    "        return mask\n",
    "    except Exception as e:\n",
    "        st.error(f\"ë§ˆìŠ¤í¬ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        return None\n",
    "\n",
    "def send_generation_request(host, params, files=None):\n",
    "    \"\"\"\n",
    "    ì´ë¯¸ì§€ ìƒì„± API ìš”ì²­ í•¨ìˆ˜\n",
    "    \n",
    "    ë§¤ê°œë³€ìˆ˜\n",
    "    host (str): API ì—”ë“œí¬ì¸íŠ¸ URL\n",
    "    params (dict): API ìš”ì²­ì— ì‚¬ìš©ë  íŒŒë¼ë¯¸í„°\n",
    "    files (dict, optional): ì—…ë¡œë“œí•  íŒŒì¼ ë°ì´í„°ë¥¼ í¬í•¨í•˜ëŠ” ë”•ì…”ë„ˆë¦¬\n",
    "    \n",
    "    ë°˜í™˜ê°’\n",
    "    requests.Response: APIë¡œë¶€í„°ì˜ ì‘ë‹µ ê°ì²´\n",
    "    \"\"\"\n",
    "    headers = {\"Accept\": \"image/*\", \"Authorization\": f\"Bearer {STABILITY_KEY}\"}\n",
    "    files = files or {}\n",
    "    \n",
    "    for key in ['image', 'mask']:\n",
    "        if key in files and isinstance(files[key], Image.Image): # 'image'ì™€ 'mask' í‚¤ì— í•´ë‹¹í•˜ëŠ” íŒŒì¼ ë°ì´í„°ë¥¼ í™•ì¸\n",
    "            img_bytes = io.BytesIO()\n",
    "            files[key].save(img_bytes, format=\"PNG\")\n",
    "            img_bytes.seek(0)\n",
    "            files[key] = img_bytes\n",
    "    \n",
    "    files = files or {\"none\": ''}\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(host, headers=headers, files=files, data=params)\n",
    "        response.raise_for_status()\n",
    "        return response\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        st.error(f\"ì´ë¯¸ì§€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        return None\n",
    "\n",
    "def translate_to_english(korean_prompt):\n",
    "    \"\"\"\n",
    "    í•œêµ­ì–´ í…ìŠ¤íŠ¸ë¥¼ ì˜ì–´ë¡œ ë²ˆì—­í•˜ëŠ” í•¨ìˆ˜\n",
    "    \n",
    "    ë§¤ê°œë³€ìˆ˜  \n",
    "    korean_prompt : ë²ˆì—­í•  í•œêµ­ì–´ í…ìŠ¤íŠ¸  \n",
    "    \n",
    "    ë°˜í™˜ê°’  \n",
    "    str: ë²ˆì—­ëœ ì˜ì–´ í…ìŠ¤íŠ¸  \n",
    "    \"\"\"\n",
    "    headers = {\"Content-Type\": \"application/json\",\"Authorization\": f\"Bearer {GPT_API_KEY}\"}\n",
    "    # gptëª¨ë¸ ë° ë©”ì„¸ì§€ ì…ë ¥ (í•œêµ­ì–´ í…ìŠ¤íŠ¸ë¥¼ ì˜ì–´ë¡œ ë²ˆì—­í•˜ë„ë¡ ìš”ì²­)\n",
    "    data = {\"model\": \"gpt-4\",\"messages\": [{\"role\": \"user\", \"content\": f\"Translate the following text to English: {korean_prompt}\"}]}\n",
    "    # openai ì‘ë‹µ ìš”ì²­ ë° ë°˜í™˜\n",
    "    try:\n",
    "        response = requests.post(\"https://api.openai.com/v1/chat/completions\", json=data, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        st.error(f\"ë²ˆì—­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        return korean_prompt\n",
    "\n",
    "\n",
    "\n",
    "def clean_vectorstore_dir(vectorstore_dir):\n",
    "    \"\"\"VectorStores ë””ë ‰í† ë¦¬ ê°•ì œ ì‚­ì œ\"\"\"\n",
    "    if os.path.exists(vectorstore_dir):\n",
    "        try:\n",
    "            # ë””ë ‰í† ë¦¬ ì‚¬ìš© ì¤‘ì¸ì§€ í™•ì¸ í›„ ì‚­ì œ\n",
    "            shutil.rmtree(vectorstore_dir)\n",
    "            print(\"VectorStores ë””ë ‰í† ë¦¬ ì‚­ì œ ì„±ê³µ\")\n",
    "        except Exception as e:\n",
    "            print(f\"ë””ë ‰í† ë¦¬ ì‚­ì œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "    else:\n",
    "        print(\"VectorStores ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# ë²¡í„° ì €ì¥ì†Œ ì´ˆê¸°í™” í•¨ìˆ˜\n",
    "def initialize_vector_store(pdf_path='data/Dress.pdf', vectorstore_dir='./VectorStores'):\n",
    "    try:\n",
    "        # ê¸°ì¡´ ë””ë ‰í† ë¦¬ ê°•ì œ ì‚­ì œ\n",
    "        clean_vectorstore_dir(vectorstore_dir)\n",
    "        \n",
    "        print(\"ìƒˆë¡œìš´ ë²¡í„° ì €ì¥ì†Œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\")\n",
    "        os.makedirs(vectorstore_dir, exist_ok=True)\n",
    "\n",
    "        # PDF ë¬¸ì„œ ë¡œë“œ\n",
    "        loader = PyPDFLoader(pdf_path)\n",
    "        documents = loader.load()\n",
    "        splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "        texts = splitter.split_documents(documents)\n",
    "\n",
    "        # ì„ë² ë”© ìƒì„±\n",
    "        embeddings = CohereEmbeddings(\n",
    "            cohere_api_key=COHERE_API_KEY, \n",
    "            user_agent=\"langchain_cohere/0.1\"\n",
    "        )\n",
    "\n",
    "        # ChromaDBì— ì €ì¥\n",
    "        vectorstore = Chroma.from_documents(\n",
    "            documents=texts,\n",
    "            embedding=embeddings,\n",
    "            persist_directory=vectorstore_dir\n",
    "        )\n",
    "        vectorstore.persist()\n",
    "        print(\"ë²¡í„° ì €ì¥ì†Œ ìƒì„± ì„±ê³µ\")\n",
    "        return vectorstore\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ë²¡í„° ì €ì¥ì†Œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_vector_store(pdf_path='data/Dress.pdf', vectorstore_dir='./VectorStores'):\n",
    "    return initialize_vector_store(pdf_path, vectorstore_dir)\n",
    "\n",
    "\n",
    "def create_retrieval_chain(vectorstore):\n",
    "    \"\"\"RAG ê²€ìƒ‰ ì²´ì¸ì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    combined_prompt = PromptTemplate(\n",
    "        template=\"\"\"\n",
    "        ì§€ê¸ˆë¶€í„° ë„ˆëŠ” 5ëª…ì˜ ì›¨ë”©ë“œë ˆìŠ¤ ì»¨ì„¤í„´íŠ¸ì•¼. 5ëª…ì´ì„œ ê°ì ì‚¬ìš©ìì˜ ì²´í˜• ë¶„ì„ì„ í†µí•´ ì¥ì ì„ ì‚´ë¦¬ê³  ë‹¨ì ì„ ë³´ì™„ í•  ìˆ˜ ìˆëŠ”\n",
    "        ì›¨ë”©ë“œë ˆìŠ¤ë¥¼ ê°ê° í•˜ë‚˜ì”© ê³ ë¥¸ ë‹¤ìŒì— ì„ ë³„í•´ì„œ ë‚˜ì˜¨ 5ê°œì˜ ì›¨ë”©ë“œë ˆìŠ¤ë¥¼\n",
    "        ì‚¬ìš©ìì˜ ì¶”ê°€ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê°€ì¥ ì–´ìš¸ë¦¬ëŠ” ë“œë ˆìŠ¤ í•˜ë‚˜ë¥¼ ì„ ì •í•´ì„œ ë³´ì—¬ì¤˜.\n",
    "        ë‹¨ ì¶”ê°€ ì •ë³´ê°€ ì—†ì„ ì‹œ ì²´í˜• ë¶„ì„ ê²°ê³¼ì˜ ì¥ì ì„ ê·¹ëŒ€í™” í•˜ê³  ë‹¨ì ì„ ìµœì†Œí™” í•  ìˆ˜ ìˆëŠ” ë“œë ˆìŠ¤ë¥¼ ì¶”ì²œí•´ì¤˜.\n",
    "        ì•„ë˜ ë‚´ìš©ì€ ì˜ˆì‹œì•¼ :\n",
    "        ì²´í˜•ë¶„ì„ : ì§ì‚¬ê°í˜•\n",
    "        ì¶”ê°€ ì •ë³´ : í™”ë ¤í•œ ìŠ¤íƒ€ì¼ ì„ í˜¸\n",
    "        \n",
    "        \n",
    "        - í—ˆë¦¬ë¼ì¸ì„ ê°•ì¡°í•˜ëŠ” ìŠ¤íƒ€ì¼\n",
    "        í—ˆë¦¬ ë¼ì¸ì„ ì‹œê°ì ìœ¼ë¡œ ê°•ì¡°í•˜ê¸° ìœ„í•´ ë²¨íŠ¸ ë””í…Œì¼ì´ ìˆê±°ë‚˜ í—ˆë¦¬ì„ ì´ ë“¤ì–´ê°„ ë“œë ˆìŠ¤ë¥¼ ì„ íƒí•˜ì„¸ìš”.\n",
    "        ì˜ˆ: Aë¼ì¸ ë“œë ˆìŠ¤, ì— íŒŒì´ì–´ ìŠ¤íƒ€ì¼ ë“œë ˆìŠ¤.\n",
    "        1. ë³¼ë¥¨ê°ì„ ë”í•˜ëŠ” ë“œë ˆìŠ¤\n",
    "        ìƒì²´ì™€ í•˜ì²´ì— ì ì ˆí•œ ë³¼ë¥¨ê°ì„ ë”í•´ ê³¡ì„ ì„ ì‚´ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "        ì˜ˆ: ë¨¸ë©”ì´ë“œ ìŠ¤íƒ€ì¼(í—ˆë¦¬ ì•„ë˜ì—ì„œ ê³¡ì„ ì„ ê°•ì¡°) ë˜ëŠ” í”Œë ˆì–´ ìŠ¤ì»¤íŠ¸ê°€ ë‹¬ë¦° ë“œë ˆìŠ¤.\n",
    "        2. ë ˆì´ìŠ¤ì™€ ì¥ì‹ ë””í…Œì¼ í™œìš©\n",
    "        ìƒì²´ë‚˜ ìŠ¤ì»¤íŠ¸ ë¶€ë¶„ì— ë ˆì´ìŠ¤, ììˆ˜, ë¹„ì¦ˆ ì¥ì‹ì„ ì¶”ê°€í•´ ì‹œì„ ì„ ë¶„ì‚°ì‹œí‚¤ê³  ìš°ì•„í•¨ì„ ë”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "        3. ë„¥ë¼ì¸ ì„ íƒ\n",
    "        ìŠ¤ìœ—í•˜íŠ¸(Sweetheart) ë„¥ë¼ì¸ì´ë‚˜ Vë„¥ì€ ëª©ì„ ì„ ê¸¸ì–´ ë³´ì´ê²Œ í•˜ê³ , ìƒì²´ì— ì—¬ì„±ìŠ¤ëŸ¬ì›€ì„ ë”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "        ê¹Šì€ ë„¤í¬ë¼ì¸ì€ ì‹œì„ ì„ ìœ„ìª½ìœ¼ë¡œ ëŒì–´ì˜¬ë ¤ ëª¸ ì „ì²´ë¥¼ ë” ê· í˜• ìˆê²Œ ë³´ì´ê²Œ í•©ë‹ˆë‹¤.\n",
    "        4. ìŠ¤ì»¤íŠ¸ ì‹¤ë£¨ì—£\n",
    "        ë³¼ ê°€ìš´(Ball gown) ìŠ¤íƒ€ì¼: í—ˆë¦¬ ì•„ë˜ë¡œ í¼ì§€ëŠ” ë””ìì¸ì€ í•˜ì²´ì— ë³¼ë¥¨ì„ ì£¼ì–´ í—ˆë¦¬ì„ ì´ ë” ì˜ ë“œëŸ¬ë‚˜ê²Œ í•©ë‹ˆë‹¤.\n",
    "        ì–¸ë°¸ëŸ°ìŠ¤ ìŠ¤ì»¤íŠ¸: ì•ì´ ì§§ê³  ë’¤ê°€ ê¸´ ë“œë ˆìŠ¤ëŠ” ì‹œì„ ì„ ë¶„ì‚°ì‹œí‚¤ë©° ë‹¤ë¦¬ë¥¼ ê¸¸ì–´ ë³´ì´ê²Œ í•©ë‹ˆë‹¤.\n",
    "        \n",
    "        ê²°ë¡  :\n",
    "        ì¶”ì²œ ì›¨ë”© ë“œë ˆìŠ¤ëŠ” ë³¼ ê°€ìš´ ìŠ¤íƒ€ì¼ì…ë‹ˆë‹¤. ë³¼ ê°€ìš´(Ball Gown)ì€ ê°€ì¥ í™”ë ¤í•˜ê³  ìš°ì•„í•œ ì›¨ë”©ë“œë ˆìŠ¤ ìŠ¤íƒ€ì¼ë¡œ,\n",
    "        í—ˆë¦¬ì—ì„œ í¼ì§€ëŠ” í’ì„±í•œ ìŠ¤ì»¤íŠ¸ê°€ ê³µì£¼í’ì˜ ë¶„ìœ„ê¸°ë¥¼ ì—°ì¶œí•©ë‹ˆë‹¤.\n",
    "        ì§ì‚¬ê°í˜• ì²´í˜•ì˜ ê· í˜•ì„ ì¡ì•„ì£¼ë©°, ë¹„ì¦ˆ, ììˆ˜, ë ˆì´ìŠ¤ ë“±ì˜ í™”ë ¤í•œ ë””í…Œì¼ì´ ë‹ë³´ì…ë‹ˆë‹¤.\n",
    "        ê¸´ íŠ¸ë ˆì¸ê³¼ ì—¬ëŸ¬ ê²¹ì˜ íŠ¤ì€ ì›…ì¥í•¨ì„ ë”í•´ íŠ¹ë³„í•œ ë‚ ì„ ë”ìš± ë¹›ëƒ…ë‹ˆë‹¤.\n",
    "        ìŠ¤ìœ—í•˜íŠ¸ ë„¥ë¼ì¸ì´ë‚˜ ì˜¤í”„ìˆ„ë” ë””ìì¸ì€ ëª©ì„ ê³¼ ì–´ê¹¨ì„ ì„ ê°•ì¡°í•˜ë©° ìš°ì•„í•¨ì„ ê·¹ëŒ€í™”í•©ë‹ˆë‹¤.\n",
    "        í¼ì§í•œ í‹°ì•„ë¼ì™€ ë°˜ì§ì´ëŠ” ì•¡ì„¸ì„œë¦¬ë¥¼ í™œìš©í•˜ë©´ ë”ìš± ë‹ë³´ì´ëŠ” ìŠ¤íƒ€ì¼ì„ ì™„ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "        í™”ë ¤í•¨ê³¼ ì›…ì¥í•¨ì„ ëª¨ë‘ ë‹´ì•„ë‚¸ ë³¼ ê°€ìš´ì€ ì‹ ë¶€ë¥¼ ê°€ì¥ ë¹›ë‚˜ê²Œ ë§Œë“¤ì–´ì£¼ëŠ” ì™„ë²½í•œ ì„ íƒì…ë‹ˆë‹¤.\n",
    "        \n",
    "        \n",
    "        ì ì´ì œ ë„ˆí¬ 5ëª…ì˜ ì›¨ë”© ë“œë ˆìŠ¤ ì»¨ì„¤í„´íŠ¸ê°€ ë¶„ì„í•´ì•¼ í•  ì¸ë¬¼ì˜ ì²´í˜• ë¶„ì„ê²°ê³¼ì™€ ì¶”ê°€ì •ë³´ì•¼. ê°€ì¥ ì í•©í•œ ì›¨ë”©ë“œë ˆìŠ¤ë¥¼ ì¶”ì²œí•´ì¤˜ :\n",
    "        ë¬¸ì„œ ë‚´ìš©: {context}\n",
    "        ì²´í˜• ë¶„ì„: {body_analysis}\n",
    "        ì¶”ê°€ ì •ë³´: {additional_info}\n",
    "        \"\"\",\n",
    "        input_variables=[\"context\", \"body_analysis\", \"additional_info\"] #input_variablesëŠ” í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì— í•„ìš”í•œ ì…ë ¥ê°’ì˜ ì´ë¦„ì„ ì •ì˜(í”„ë¡¬í”„íŠ¸ ì•ˆì— ë„£ìœ¼ë©´ ì´ê³³ì—ë„ ë„£ì„ê²ƒ!)\n",
    "    )\n",
    "    \n",
    "    llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.3, openai_api_key=GPT_API_KEY)\n",
    "    llm_chain = LLMChain(llm=llm, prompt=combined_prompt)         #     ì—¬ê¸°ì— í”„ë¡¬í”„íŠ¸ ì§ì ‘ì ìœ¼ë¡œ ë“¤ì–´ê°\n",
    "    \n",
    "    # ì—¬ëŸ¬ ë¬¸ì„œë¥¼ í•˜ë‚˜ì˜ í”„ë¡¬í”„íŠ¸ë¡œ ê²°í•©í•´ LLMì— ì „ë‹¬í•˜ëŠ” ì²´ì¸\n",
    "    return StuffDocumentsChain(llm_chain=llm_chain, document_variable_name=\"context\")\n",
    "    \n",
    "\n",
    "def send_gpt_request_with_rag(body_analysis, additional_info, pdf_path='data/Dress.pdf', vectorstore_dir='./VectorStores'):\n",
    "    \"\"\"RAG ê¸°ë°˜ ë“œë ˆìŠ¤ ì¶”ì²œ í•¨ìˆ˜\"\"\"\n",
    "    try:\n",
    "        # ë²¡í„° ì €ì¥ì†Œ ì´ˆê¸°í™”\n",
    "        vectorstore = initialize_vector_store(pdf_path, vectorstore_dir)\n",
    "        if vectorstore is None:\n",
    "            return \"ë²¡í„° ì €ì¥ì†Œë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "        \n",
    "        # RAG ì²´ì¸ ìƒì„±\n",
    "        rag_chain = create_retrieval_chain(vectorstore)\n",
    "        \n",
    "        # ë¬¸ì„œ ê²€ìƒ‰ ë° RAG ì²´ì¸ ì‹¤í–‰\n",
    "        retrieved_docs = vectorstore.similarity_search(\"ì›¨ë”©ë“œë ˆìŠ¤ ìŠ¤íƒ€ì¼ ì¶”ì²œ\")\n",
    "        \n",
    "        rag_result = rag_chain({\n",
    "            \"input_documents\": retrieved_docs,  # ê²€ìƒ‰ëœ ë¬¸ì„œ\n",
    "            \"body_analysis\": body_analysis,     # ì²´í˜• ë¶„ì„ ì •ë³´\n",
    "            \"additional_info\": additional_info  # ì¶”ê°€ ì‚¬ìš©ì ì •ë³´\n",
    "        })\n",
    "\n",
    "        # ê²°ê³¼ ì •ë¦¬\n",
    "        korean_recommendation = rag_result['output_text'] # RAG ê²°ê³¼ì—ì„œ ì¶œë ¥ëœ í•œêµ­ì–´ ì¶”ì²œ ê²°ê³¼ë¥¼ ì €ì¥\n",
    "        english_translation = translate_to_english(korean_recommendation)  # ë²ˆì—­ í•¨ìˆ˜ í˜¸ì¶œí•˜ì—¬ ì¶”ì²œ ê²°ê³¼ë¥¼ ì˜ì–´ë¡œ ë²ˆì—­\n",
    "\n",
    "        # ê²°ê³¼ë¥¼ PDF ë°ì´í„°ì—ì„œ ì¶”ì¶œëœ ì„¸ë¶€ ì •ë³´ë¡œ ì •ë¦¬\n",
    "        korean_recommendation = f\"\"\"\n",
    "        ğŸŒŸì²´í˜•ì— ì–´ìš¸ë¦¬ëŠ” ì›¨ë”©ë“œë ˆìŠ¤ ì¶”ì²œ ê²°ê³¼ğŸŒŸ\n",
    "        \n",
    "        ğŸ”¹ ì²´í˜• ë¶„ì„ ê²°ê³¼ : {body_analysis}\n",
    "        ğŸ”¹ ì¶”ê°€ ì •ë³´ : {additional_info}\n",
    "        \n",
    "        ğŸ”¹ ì¶”ì²œ ë“œë ˆìŠ¤ ìŠ¤íƒ€ì¼\n",
    "        {korean_recommendation}\n",
    "        \"\"\"\n",
    "        return korean_recommendation\n",
    "\n",
    "    except Exception as e:\n",
    "        st.error(f\"ì¶”ì²œ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        return \"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "# ë°”ë”” í˜•íƒœ ì •ì˜\n",
    "def classify_body_shape(measurements):\n",
    "    shoulder_width = measurements['shoulder_width']\n",
    "    chest = measurements['chest']\n",
    "    waist = measurements['waist']\n",
    "    hip = measurements['hip']\n",
    "    waist_width = measurements['waist_width']\n",
    "    hip_width = measurements['hip_width']\n",
    "    height = measurements['height']\n",
    "    weight = measurements['weight']\n",
    "    bmi = weight / ((height / 100) ** 2)\n",
    "\n",
    "    if (chest > waist * 1.25 or hip > waist * 1.25) and \\\n",
    "       abs(chest - hip) <= 10 and abs(waist_width - hip_width) <= 5:\n",
    "        body_shape = \"ëª¨ë˜ì‹œê³„í˜•\"\n",
    "\n",
    "    elif shoulder_width > hip * 1.05 and chest > hip * 1.05:\n",
    "        body_shape = \"ì—­ì‚¼ê°í˜•\"\n",
    "\n",
    "    elif (waist / chest >= 0.9) and abs(chest - hip) <= 10 and abs(shoulder_width - hip) <= 5:\n",
    "        body_shape = \"ì§ì‚¬ê°í˜•\"\n",
    "\n",
    "    elif waist / hip >= 0.9 and bmi >= 23:\n",
    "        body_shape = \"ì›í˜•\"\n",
    "\n",
    "    else:\n",
    "        body_shape = \"ì¼ë°˜í˜•\"\n",
    "\n",
    "    if bmi < 18:\n",
    "        size_category = \"ë§ˆë¦„\"\n",
    "    elif 18 <= bmi < 23:\n",
    "        size_category = \"í‘œì¤€\"\n",
    "    elif 23 <= bmi < 25:\n",
    "        size_category = \"ê³¼ì²´ì¤‘\"\n",
    "    else:\n",
    "        size_category = \"ë¹„ë§Œ\"\n",
    "\n",
    "    return f\"{body_shape}\"\n",
    "\n",
    "def main():\n",
    "    st.set_page_config(page_title=\"ì²´í˜•ì— ë§ëŠ” ì›¨ë”© ë“œë ˆìŠ¤ AI ì¶”ì²œ\", page_icon=\"ğŸ‘—\")\n",
    "    st.title(\"âœ¨ì›¨ë”© ë“œë ˆìŠ¤ ì¶”ì²œâœ¨\")\n",
    "\n",
    "    with st.sidebar:\n",
    "        st.header(\"ì‹ ì²´ ì •ë³´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”\")\n",
    "        measurements = {\n",
    "            \"shoulder_width\": st.number_input(\"ì–´ê¹¨ ë„ˆë¹„ (cm)\", min_value=30.0, max_value=80.0, step=0.1),   # ë„“ì€ ë²”ìœ„: 30~80cm\n",
    "            \"chest\": st.number_input(\"ê°€ìŠ´ ë‘˜ë ˆ (cm)\", min_value=70.0, max_value=160.0, step=0.1),         # ë„“ì€ ë²”ìœ„: 70~160cm\n",
    "            \"waist\": st.number_input(\"í—ˆë¦¬ ë‘˜ë ˆ (cm)\", min_value=45.0, max_value=140.0, step=0.1),         # ë„“ì€ ë²”ìœ„: 45~140cm\n",
    "            \"hip\": st.number_input(\"ì—‰ë©ì´ ë‘˜ë ˆ (cm)\", min_value=70.0, max_value=160.0, step=0.1),         # ë„“ì€ ë²”ìœ„: 70~160cm\n",
    "            \"waist_width\": st.number_input(\"í—ˆë¦¬ ë„ˆë¹„ (cm)\", min_value=20.0, max_value=70.0, step=0.1),    # ë„“ì€ ë²”ìœ„: 20~70cm\n",
    "            \"hip_width\": st.number_input(\"ì—‰ë©ì´ ë„ˆë¹„ (cm)\", min_value=30.0, max_value=80.0, step=0.1),    # ë„“ì€ ë²”ìœ„: 30~80cm\n",
    "            \"height\": st.number_input(\"í‚¤ (cm)\", min_value=130.0, max_value=210.0, step=0.1),             # ë„“ì€ ë²”ìœ„: 130~210cm\n",
    "            \"weight\": st.number_input(\"ì²´ì¤‘ (kg)\", min_value=30.0, max_value=150.0, step=0.1),            # ë„“ì€ ë²”ìœ„: 30~150kg\n",
    "        }\n",
    "\n",
    "        face_shape = st.selectbox(\"ì–¼êµ´í˜• ì„ íƒ\", [\"ë‘¥ê·¼í˜•\", \"ê³„ë€í˜•\", \"ê°ì§„í˜•\", \"ì—­ì‚¼ê°í˜•\"])\n",
    "        additional_info = st.text_area(\"ì¶”ê°€ ì •ë³´ (ì˜ˆ: í”¼ë¶€ í†¤, ìŠ¤íƒ€ì¼ ì„ í˜¸ë„ ë“±)\")\n",
    "        image_file = st.file_uploader(\"ì´ë¯¸ì§€ ì—…ë¡œë“œ\", type=[\"jpg\", \"png\", \"jpeg\"])\n",
    "        recommend_button = st.button(\"ì¶”ì²œ ë° ì´ë¯¸ì§€ ìƒì„±\")\n",
    "    \n",
    "    tab1, tab2 = st.tabs([\"ì¶”ì²œ\", \"ì§ˆë¬¸\"])\n",
    "    \n",
    "    with tab1:\n",
    "        # ì¶”ì²œ ë° ì´ë¯¸ì§€ ìƒì„± ë²„íŠ¼ì´ ëˆŒë¦¬ë©´ session_state ì´ˆê¸°í™”\n",
    "        if recommend_button:\n",
    "            st.session_state.pop(\"generated_text\", None)  # ì´ì „ í…ìŠ¤íŠ¸ ì œê±°\n",
    "            st.session_state.pop(\"generated_image\", None)  # ì´ì „ ì´ë¯¸ì§€ ì œê±°\n",
    "    \n",
    "        # ì´ì „ì— ìƒì„±í•œ í…ìŠ¤íŠ¸ë‚˜ ì´ë¯¸ì§€ê°€ session_stateì— ìˆë‹¤ë©´ í‘œì‹œ\n",
    "        if \"generated_text\" in st.session_state and \"generated_image\" in st.session_state:\n",
    "            st.subheader(\"ì¶”ì²œëœ ì›¨ë”©ë“œë ˆìŠ¤ ìŠ¤íƒ€ì¼\")\n",
    "            st.write(st.session_state[\"generated_text\"])\n",
    "            st.image(st.session_state[\"generated_image\"], caption=\"AIê°€ ì¶”ì²œí•œ ë“œë ˆìŠ¤ë¥¼ ì…ì€ ì•„ë¦„ë‹¤ìš´ ì‹ ë¶€\", use_container_width=True)\n",
    "        else:\n",
    "            # ì¶”ì²œ í™”ë©´ í‘œì‹œ ë° ì´ë¯¸ì§€ ìƒì„±í•˜ëŠ” ë²„íŠ¼\n",
    "            if recommend_button:\n",
    "                if image_file:\n",
    "                    # ë¡œë”© ì¤‘ ë©”ì‹œì§€ ì¶œë ¥\n",
    "                    loading_placeholder = st.empty()\n",
    "                    result_placeholder = st.empty()\n",
    "    \n",
    "                    loading_placeholder.text(\"ğŸ”„ ê²°ê³¼ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤...\")\n",
    "                    time.sleep(3)\n",
    "                    loading_placeholder.empty()  # ë¡œë”© ìƒíƒœ ì§€ìš°ê¸°\n",
    "                    result_placeholder.text(\"ğŸ”„ ê²°ê³¼ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤...\")\n",
    "    \n",
    "                    try:\n",
    "                        with loading_placeholder.container():\n",
    "                            st.spinner(\"ì¶”ì²œ ë° ì´ë¯¸ì§€ ìƒì„± ì¤‘...\")\n",
    "                            st.progress(0)\n",
    "    \n",
    "                        time.sleep(1)\n",
    "                        # ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹œì‘\n",
    "                        image = Image.open(image_file)\n",
    "                        mask_image = create_mask_from_image(image)\n",
    "                        mask_pil_image = Image.fromarray(mask_image)\n",
    "    \n",
    "                        with loading_placeholder.container():\n",
    "                            st.spinner(\"ì¶”ì²œ ìŠ¤íƒ€ì¼ ë¶„ì„ ì¤‘...\")\n",
    "                            st.progress(30)\n",
    "    \n",
    "                        # ì¶”ì²œ ìƒì„±\n",
    "                            body_analysis = classify_body_shape(measurements)\n",
    "                            korean_recommendation = send_gpt_request_with_rag(body_analysis, additional_info)\n",
    "    \n",
    "                        with loading_placeholder.container():\n",
    "                            st.spinner(\"ì´ë¯¸ì§€ ìƒì„± ì¤€ë¹„ ì¤‘...\")\n",
    "                            st.progress(60)\n",
    "    \n",
    "                        # ì¶”ì²œ ì˜ì–´ë¡œ ë²ˆì—­\n",
    "                        english_translation = translate_to_english(korean_recommendation)\n",
    "                        # ì´ë¯¸ì§€ ìƒì„±\n",
    "                        params = {\n",
    "                            \"prompt\": f\"Design a wedding dress suitable for a {body_analysis} body type. \",\n",
    "                            \"negative_prompt\": \"low quality, blurry, poorly detailed, overly dark, cartoonish, grainy\",\n",
    "                            \"seed\": 42,\n",
    "                            \"mode\": \"mask\",\n",
    "                            \"output_format\": \"jpeg\",\n",
    "                        }\n",
    "    \n",
    "                        with loading_placeholder.container():\n",
    "                            st.spinner(\"ìµœì¢… ì´ë¯¸ì§€ ìƒì„± ì¤‘...\")\n",
    "                            st.progress(80)\n",
    "    \n",
    "                        response = send_generation_request(STABILITY_API_HOST, params, files={\"image\": image, \"mask\": mask_pil_image})\n",
    "                        output_image = response.content\n",
    "                        edited_image = Image.open(io.BytesIO(output_image))\n",
    "    \n",
    "                        # ë¡œë”© ìŠ¤í”¼ë„ˆ ì§€ìš°ê¸°\n",
    "                        loading_placeholder.empty()\n",
    "    \n",
    "                        # ê²°ê³¼ í‘œì‹œ\n",
    "                        with result_placeholder.container():\n",
    "                            st.subheader(\"ì¶”ì²œëœ ì›¨ë”©ë“œë ˆìŠ¤ ìŠ¤íƒ€ì¼\")\n",
    "                            st.write(korean_recommendation)\n",
    "                            st.image(edited_image, caption=\"ì¶”ì²œ ì´ë¯¸ì§€\", use_container_width=True)\n",
    "    \n",
    "                        # session_stateì— ê²°ê³¼ ì €ì¥ -> íƒ­ ì´ë™ ì‹œ ìœ ì§€\n",
    "                        st.session_state[\"generated_text\"] = korean_recommendation\n",
    "                        st.session_state[\"generated_image\"] = edited_image\n",
    "    \n",
    "                    except Exception as e:\n",
    "                        loading_placeholder.empty()\n",
    "                        st.error(f\"ì˜¤ë¥˜: {e}\")\n",
    "                else:\n",
    "                    st.warning(\"ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.\")\n",
    "            else:\n",
    "                st.info(\"ğŸ“„ ì‚¬ì´ë“œë°”ì—ì„œ ì‹ ì²´ ì •ë³´ì™€ ì´ë¯¸ì§€ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.\")\n",
    "\n",
    "\n",
    "    with tab2:\n",
    "        st.title(\"ê¶ê¸ˆí•œ ê±° ë¬¼ì–´ë´ğŸ’¬\")\n",
    "      \n",
    "        def moderate_message(message):\n",
    "            client = OpenAI(api_key=GPT_API_KEY)\n",
    "            response = client.moderations.create(model='text-moderation-latest', input=message) # OpenAI Moderation API ëª¨ë¸ ì„¤ì •  í˜„ì¬ ê°€ì¥ ì í•©\n",
    "            moderation_result = response.results[0] \n",
    "\n",
    "            if moderation_result.flagged: # ë©”ì‹œì§€ê°€ ë¶€ì ì ˆí•˜ë‹¤ê³  íŒë‹¨ëœ ê²½ìš°\n",
    "                category_type = dict(response.results[0].categories)\n",
    "                categories = [i for i, j in category_type.items() if j]\n",
    "                return False, categories\n",
    "\n",
    "            return True, None\n",
    "        # ë¶€ì ì ˆí•œ ë©”ì‹œì§€ ì°¨ë‹¨\n",
    "        class ModeratedLLMChain(LLMChain):\n",
    "            def moderate_and_generate(self, user_input):\n",
    "                is_safe, categories = moderate_message(user_input)\n",
    "                if not is_safe:                   # ì…ë ¥ì´ ë¶€ì ì ˆí•˜ë©´ ê²½ê³  ë©”ì‹œì§€ ì¶œë ¥\n",
    "                    st.write(f\"ì‚¬ìš©ìì˜ ë©”ì‹œì§€ê°€ ë¶€ì ì ˆí•œ ì½˜í…ì¸ ë¡œ íŒë‹¨ë˜ì–´ ì°¨ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤: {categories}\")\n",
    "                    return \"\"\n",
    "\n",
    "                response = self.predict(question=user_input)\n",
    "\n",
    "                is_safe_ai, categories_ai = moderate_message(response)\n",
    "                if not is_safe_ai:\n",
    "                    st.write(f\"AIì˜ ì‘ë‹µì´ ë¶€ì ì ˆí•œ ì½˜í…ì¸ ë¡œ íŒë‹¨ë˜ì–´ ì°¨ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤: {categories_ai}\")\n",
    "                    return \"\"\n",
    "\n",
    "                # AI ì‘ë‹µ ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ í‘œì‹œ\n",
    "                words = response.split()\n",
    "                chunk_size = 1\n",
    "                full_response = \"\"     # ì „ì²´ ì‘ë‹µì„ ëˆ„ì í•  ë¬¸ìì—´ ì´ˆê¸°í™”\n",
    "                empty = st.empty()\n",
    "\n",
    "                for i in range(0, len(words), chunk_size):\n",
    "                    full_response += \" \".join(words[i:i + chunk_size]) + \" \"\n",
    "                    empty.write(full_response, unsafe_allow_html=True)\n",
    "                    time.sleep(0.1)\n",
    "\n",
    "                return full_response\n",
    "         # gptëª¨ë¸ ìƒì„¸ ì„¤ì •\n",
    "        chat_model = ChatOpenAI(model_name='gpt-4o', api_key=GPT_API_KEY, temperature=0.7)\n",
    "\n",
    "        my_prompt = PromptTemplate(input_variables=[\"chat_history\", \"question\"],\n",
    "                                   template=\"\"\"You are an AI assistant.\n",
    "                                   You are currently having a conversation with a human.\n",
    "                                   Answer the questions.                       \n",
    "                                   chat_history: {chat_history},\n",
    "                                   Human: {question}\n",
    "                                   AI assistant: \"\"\")\n",
    "           \n",
    "        if \"pre_memory\" not in st.session_state:          # ëŒ€í™” ê¸°ë¡ ë©”ëª¨ë¦¬ (ì„¸ì…˜ ìƒíƒœì— ì €ì¥)\n",
    "            st.session_state.pre_memory = ConversationBufferMemory(memory_key=\"chat_history\",return_messages=True)\n",
    "\n",
    "        # ModeratedLLMChain ê°ì²´ ìƒì„± (ëŒ€í™” ë‚´ìš©ì„ í•„í„°ë§í•˜ê³  ì‘ë‹µ ìƒì„±)\n",
    "        moderated_chain = ModeratedLLMChain(llm=chat_model, prompt=my_prompt, memory=st.session_state.pre_memory)\n",
    "\n",
    "        if \"messages\" not in st.session_state:\n",
    "            st.session_state.messages = [\n",
    "                {\"role\": \"assistant\", \"content\": \"ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” ë‹¹ì‹ ì˜ ë“œë ˆìŠ¤ ì¶”ì²œ ì „ë¬¸ AIì…ë‹ˆë‹¤.\"}\n",
    "            ]\n",
    "\n",
    "        for message in st.session_state.messages:\n",
    "            with st.chat_message(message[\"role\"]):\n",
    "                st.write(message[\"content\"])\n",
    "\n",
    "        user_prompt = st.chat_input()    # ì±„íŒ… ì…ë ¥ í•„ë“œ ìƒì„±\n",
    "\n",
    "        if user_prompt is not None:\n",
    "            st.session_state.messages.append({\"role\": \"user\", \"content\": user_prompt})\n",
    "            with st.chat_message(\"user\"):\n",
    "                st.write(user_prompt)\n",
    "\n",
    "        if st.session_state.messages[-1][\"role\"] != \"assistant\":\n",
    "            with st.chat_message(\"assistant\"):\n",
    "                try:\n",
    "                    ai_response = moderated_chain.moderate_and_generate(user_prompt)\n",
    "                    st.session_state.messages.append({\"role\": \"assistant\", \"content\": ai_response})\n",
    "                except Exception as e:\n",
    "                    st.error(f\"LLM ì—ëŸ¬ ë°œìƒ: {e}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":     #\"ì´ íŒŒì¼ì„ í˜¼ì ì‹¤í–‰í•  ë•Œë§Œ ì´ ì½”ë“œë¥¼ ì‹¤í–‰í•´!\" ë¼ëŠ” ëœ»\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09ca560-f832-43a4-aac2-3f8da875a701",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
